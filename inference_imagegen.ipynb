{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now reload and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from load_dataset import load_dataset\n",
    "\n",
    "INPUT_SIZE = (1,448,448)\n",
    "\n",
    "infer_dataset = load_dataset(\n",
    "    \"cxr8\",\n",
    "    input_size=INPUT_SIZE,\n",
    "    clahe_tile_size=8,\n",
    ")\n",
    "\n",
    "for n in range(10):\n",
    "    print(f\"{infer_dataset.imgs[n][0]} {infer_dataset[n][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from vae import VAE, vae_loss\n",
    "\n",
    "KERNEL_SIZE = 11\n",
    "DIRECTIONS = 7\n",
    "LATENT_DIM = 32  # 64\n",
    "show_summary = True\n",
    "\n",
    "# model = VAE((1 if dataset_name == \"cxr8\" else 3, 224, 224), latent_dim).to(device)\n",
    "model = VAE(INPUT_SIZE, init_kernel_size=KERNEL_SIZE, latent_dim=LATENT_DIM)\n",
    "model.load_state_dict(torch.load(\"weights/20230425175434_clahe8_kernel11_latent32_orisq.zip\"))\n",
    "if show_summary:\n",
    "    print(\n",
    "        summary(\n",
    "            model,\n",
    "            input_size=(37, INPUT_SIZE[0], INPUT_SIZE[1], INPUT_SIZE[2]),\n",
    "            depth=10,\n",
    "            col_names=[\n",
    "                \"input_size\",\n",
    "                \"kernel_size\",\n",
    "                \"mult_adds\",\n",
    "                \"num_params\",\n",
    "                \"output_size\",\n",
    "                \"trainable\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "model = model.cpu()\n",
    "if False:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(set([p.device for p in model.parameters()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20,8))\n",
    "\n",
    "for n in range(5):\n",
    "    print(f\"{infer_dataset.imgs[n][0]} {infer_dataset[n][0].shape}\")\n",
    "\n",
    "    # batch = batch.cpu()\n",
    "    latent_vec = model.encoder(torch.unsqueeze(infer_dataset[n][0], 0))\n",
    "    print(latent_vec[0].detach().numpy())\n",
    "    recon_batch, mu, log_var = model(infer_dataset[n][0])\n",
    "    # print(recon_batch.shape)\n",
    "\n",
    "    # print(v.shape)\n",
    "    ax[0][n].imshow(torch.squeeze(infer_dataset[n][0]), cmap='bone')\n",
    "    ax[1][n].imshow(torch.squeeze(recon_batch.detach()), cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "reconst_base_path = Path(\"C:\\Temp\\cxr8\")\n",
    "print(reconst_base_path)\n",
    "\n",
    "for n in range(1000):\n",
    "    orig_path = Path(infer_dataset.imgs[n][0])\n",
    "    print(f\"{orig_path.stem} {infer_dataset[n][0].shape}\")\n",
    "\n",
    "    latent_vec = model.encoder(torch.unsqueeze(infer_dataset[n][0], 0))\n",
    "    latent_vec = latent_vec[0][0].detach().numpy()\n",
    "    with open(f\"{reconst_base_path}/latent_vecs.csv\", \"a\") as f:\n",
    "        f.write(f\"{orig_path.stem},\")\n",
    "        f.write(\",\".join([f\"{e:.6f}\" for e in latent_vec]))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # print(latent_vec[0].detach().numpy())\n",
    "\n",
    "    reconst, mu, log_var = model(infer_dataset[n][0])\n",
    "\n",
    "    reconst = torch.squeeze(reconst).detach().numpy() * 255.0\n",
    "    reconst = reconst.astype(np.uint8)\n",
    "    # print(reconst[0])\n",
    "    im = Image.fromarray(reconst)\n",
    "    # print(im)\n",
    "\n",
    "    reconst_path = reconst_base_path / f\"{orig_path.stem}-reconst.png\"\n",
    "    print(f\"Saving to {reconst_path}\")\n",
    "    im.save(reconst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
